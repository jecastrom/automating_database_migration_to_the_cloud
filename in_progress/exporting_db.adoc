:stylesheet: boot-darkly.css
:linkcss: boot-darkly.css
:my-name: Jorge Castro DAPT NOV2021
:description:
//:fn-xxx: Add the explanation foot note here bla bla
ifdef::env-github[]
:sectnums:
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:experimental:
:table-caption!:
:example-caption!:
:figure-caption!:
:idprefix:
:idseparator: -
:linkattrs:
:banner: https://user-images.githubusercontent.com/63274055/160799043-88e475e5-35bf-4e8f-95f2-4e479764b470.png
:fontawesome-ref: http://fortawesome.github.io/Font-Awesome
:icon-inline: {user-ref}/#inline-icons
:icon-attribute: {user-ref}/#size-rotate-and-flip
:video-ref: {user-ref}/#video
:checklist-ref: {user-ref}/#checklists
:list-marker: {user-ref}/#custom-markers
:list-number: {user-ref}/#numbering-styles
:imagesdir-ref: {user-ref}/#imagesdir
:image-attributes: {user-ref}/#put-images-in-their-place
:toc-ref: {user-ref}/#table-of-contents
:para-ref: {user-ref}/#paragraph
:literal-ref: {user-ref}/#literal-text-and-blocks
:admon-ref: {user-ref}/#admonition
:bold-ref: {user-ref}/#bold-and-italic
:quote-ref: {user-ref}/#quotation-marks-and-apostrophes
:sub-ref: {user-ref}/#subscript-and-superscript
:mono-ref: {user-ref}/#monospace
:css-ref: {user-ref}/#custom-styling-with-attributes
:pass-ref: {user-ref}/#passthrough-macros
endif::[]
ifndef::env-github[]
:imagesdir: ./
endif::[]

image::{banner}[width=1200]


== Creating a dump of a locally hosted DB instance (Logical backup)

MySQL Shell has three utility functions for dumping Tables, Schemas and instances:

* util.dumpTables()

* Util.dumpSchema()

* Util:dumpInstance()

For loading:

* util.loadDump

Here I will be focusing on the dump instance. This function has an array of options, very granular to specify arguments to filter what we need or do not need in our instance dump such as specified schemas and tables, users and their roles and grants, events, routines, and triggers from the import.

Users and their roles and grants are excluded from the load by default.

Before running the dump, we have the option to do a `dry run`, which will only show us what actions would be performed when we run the utility for real with the options we select.

```
util.dumpInstance("C:/Users/jcast/testdump/my_instance_dump", {dryRun: true})
```


[NOTE]
====
 * MySQL shell must be run as Administrator, otherwise we will have an error message:

 `Util.dumpSchemas: Could not create directory
 \\?\C:\Program Files\MySQL\MySQL Shell 8.0\bin\sak-aws: 
 Access is denied. (RuntimeError)`

* The dump and load utilities must be run in JavaScript or Python mode.
* The minimum required set of privileges of the user account used to run the utility are:
 `BACKUP_ADMIN`, `EVENT`, `RELOAD`, `SELECT`, `SHOW VIEW`, and `TRIGGER`.

 * Depending on the use case, If the `binary log` is required to be included in the dump, the user running the utility needs `REPLICATION CLIENT` privileges. Otherwise the dump will continue as normal but without the `binary log`. A warning message is displayed:

 ```
 WARNING: Could not fetch the binary log information: MySQL Error 1227 (42000): 
 Access denied; you need (at least one of) the SUPER, REPLICATION CLIENT privilege(s) for this operation
 ```
====



First we log in to the MySQL Shell with the MySQL credentials. Then we find out the MySQL server version we are running (Top left of the shell). We will need that information to provision the RDS instance.

We run the following command to create the logical backup:



```js
\connect backup_user@localhost
```
```js
util.dumpInstance("C:/Users/jcast/data/my_dump_schema")
```


Data files produced by the MySQL Shell Schema Dump Utility include DDL files for creating the schema structure, compressed .tsv files that contain the data, and .json metadata files.

Unlike the `mysqldump` utility that outputs only one file, `Utility Dump Schema, Instance and Table` generate a dump directory containing several files, so its divided in several chunks.

The utility does this to increase performance on data streaming. Instead of having only one file with create table statements, one after the other, the tables are spread in different chucks and loaded in parallel, all at the same time with a high number of simultaneous threads connections to the new instance.

image::https://user-images.githubusercontent.com/63274055/160140660-1174385a-fe12-4549-8f1e-ff3846750cca.png[width=600]
====
''''
====

== Creating a dump of the entire database instance (Total of 10 schemas. 60 million rows)




image::https://github.com/jecastrom/automating_database_migration_to_the_cloud/blob/main/img/instancedump.gif[width=800]


====
''''
====




[.result]
====
[cols="1,1,1,1", options="header"]
.Applications
|===
|Option
|Value
|Default
|Example

|Firefox
|Browser
|Mozilla Firefox is an open-source web browser.
It's designed for standards compliance,
performance, portability.

|Arquillian
|Testing
|An innovative and highly extensible testing platform.
Empowers developers to easily create real, automated tests.
|Firefox
|Browser
|Mozilla Firefox is an open-source web browser.
It's designed for standards compliance,
performance, portability.

|===
====


.Table Title
|===
|Name of Column 1 |Name of Column 2 |Name of Column 3 (1)
(2)
|Cell in column 1, row 1
|Cell in column 2, row 1
|Cell in column 3, row 1

|Cell in column 1, row 2
|Cell in column 2, row 2
|Cell in column 3, row 2
|===


