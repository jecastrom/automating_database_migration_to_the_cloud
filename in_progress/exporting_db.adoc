:stylesheet: boot-darkly.css
:linkcss: boot-darkly.css
:my-name: Jorge Castro DAPT NOV2021
:description:
//:fn-xxx: Add the explanation foot note here bla bla
ifdef::env-github[]
:sectnums:
:tip-caption: :bulb:
:note-caption: :information_source:
:important-caption: :heavy_exclamation_mark:
:caution-caption: :fire:
:warning-caption: :warning:
:experimental:
:table-caption!:
:example-caption!:
:figure-caption!:
:idprefix:
:idseparator: -
:linkattrs:
:banner: https://user-images.githubusercontent.com/63274055/160799043-88e475e5-35bf-4e8f-95f2-4e479764b470.png
:fontawesome-ref: http://fortawesome.github.io/Font-Awesome
:icon-inline: {user-ref}/#inline-icons
:icon-attribute: {user-ref}/#size-rotate-and-flip
:video-ref: {user-ref}/#video
:checklist-ref: {user-ref}/#checklists
:list-marker: {user-ref}/#custom-markers
:list-number: {user-ref}/#numbering-styles
:imagesdir-ref: {user-ref}/#imagesdir
:image-attributes: {user-ref}/#put-images-in-their-place
:toc-ref: {user-ref}/#table-of-contents
:para-ref: {user-ref}/#paragraph
:literal-ref: {user-ref}/#literal-text-and-blocks
:admon-ref: {user-ref}/#admonition
:bold-ref: {user-ref}/#bold-and-italic
:quote-ref: {user-ref}/#quotation-marks-and-apostrophes
:sub-ref: {user-ref}/#subscript-and-superscript
:mono-ref: {user-ref}/#monospace
:css-ref: {user-ref}/#custom-styling-with-attributes
:pass-ref: {user-ref}/#passthrough-macros
endif::[]
ifndef::env-github[]
:imagesdir: ./
endif::[]

image::{banner}[width=1200]


== Creating a dump of a locally hosted DB instance (Logical backup)

MySQL Shell has three utility functions for dumping Tables, Schemas and instances:

* util.dumpTables()

* Util.dumpSchema()

* Util:dumpInstance()

For loading:

* util.loadDump

Here I will be focusing on the dump instance. This function has an array of options, very granular to specify arguments to filter what we need or do not need in our instance dump such as specified schemas and tables, users and their roles and grants, events, routines, and triggers from the import.

Users and their roles and grants are excluded from the load by default.

Before running the dump, we have the option to do a `dry run`, which will only show us what actions would be performed when we run the utility for real with the options we select.

```
util.dumpInstance("C:/Users/jcast/testdump/my_instance_dump", {dryRun: true})
```


[NOTE]
====
 * MySQL shell must be run as Administrator, otherwise we will have an error message:

 `Util.dumpSchemas: Could not create directory
 \\?\C:\Program Files\MySQL\MySQL Shell 8.0\bin\sak-aws: 
 Access is denied. (RuntimeError)`

* The dump and load utilities must be run in JavaScript or Python mode.
* The minimum required set of privileges of the user account used to run the utility are:
 `BACKUP_ADMIN`, `EVENT`, `RELOAD`, `SELECT`, `SHOW VIEW`, and `TRIGGER`.

 * Depending on the use case, If the `binary log` is required to be included in the dump, the user running the utility needs `REPLICATION CLIENT` privileges. Otherwise the dump will continue as normal but without the `binary log`. A warning message is displayed:

 
 WARNING: Could not fetch the binary log information: MySQL Error 1227 (42000): 
 Access denied; you need (at least one of) the SUPER, REPLICATION CLIENT privilege(s) for this operation
 
====

=== Creating a dump directly onto a cloud storage bucket

The MySQL Shell Dump Utilities support the export directly into a `Oracle Cloud Infrastructure Object Storage bucket`. However to export a dump into an AWS S3 is currently not supportted:

WARNING: Util.dumpInstance: Directory handling for s3 protocol is not supported. (ArgumentError)

====
''''
====

First we log in to the MySQL Shell with the MySQL credentials. Then we find out the MySQL server version we are running (Top left of the shell). We will need that information to provision the RDS instance.

We run the following command to create the logical backup:



```js
\connect backup_user@localhost
```
```js
util.dumpInstance("C:/Users/jcast/data/my_dump_schema")
```


Data files produced by the MySQL Shell Schema Dump Utility include DDL files for creating the schema structure, compressed .tsv files that contain the data, and .json metadata files.

Unlike the `mysqldump` utility that outputs only one file, `Utility Dump Schema, Instance and Table` generate a dump directory containing several files, so its divided in several chunks.

The utility does this to increase performance on data streaming. Instead of having only one file with create table statements, one after the other, the tables are spread in different chucks and loaded in parallel, all at the same time with a high number of simultaneous threads connections to the new instance.




image::https://user-images.githubusercontent.com/63274055/160140660-1174385a-fe12-4549-8f1e-ff3846750cca.png[width=600]




====
''''
====

Here is a recap of the options available for this function: For more details on this options, go to the documentation for the Dump Instance Utility at the footer of this page.


[.result]
====
[cols="1,1,1,1,1", options="header"]
.Dump: Options for Dump Control
|===
|Option
|Value
|Default
|Example
|Description

|dryRun
|true / false
|false
|util.dumpInstance("C:/data/instance_dump", {dryRun: true})
|Display information about what would be dumped with the specified set of options

|threads
|integer
|4
|util.dumpInstance("C:/data/inst_dump", {threads: 88})
|The number of parallel threads to use to dump chunks of data from the MySQL instance.

|defaultCharacterSet
|"string"
|utf8mb4
|util.dumpInstance("C:/data/inst_dump", {defaultCharacterSet: "utf8mb4"})
|The character set to be used during the session connections that are opened by MySQL Shell to the server for the dump

|===
====

====
''''
====



[.result]
====
[cols="1,1,1,1,1", options="header"]
.Dump: Options for filtering
|===
|Option
|Value
|Default
|Example
|Description

|dataOnly
|true / false
|false
|util.dumpInstance("C:/data/instance_dump", {dataOnly: true})
|Setting this option to `true` includes only the data files for the dumped items in the dump, and does not include DDL files.

|users
|true / false
|true
|util.dumpInstance("C:/data/inst_dump", {users: false})
|Include (true) or exclude (false) users and their roles and grants in the dump

|excludeUsers
|array of strings
|----
|util.dumpInstance("C:/data/inst_dump", {excludeUsers: ["'user_name'@'host_name'"]})
|Exclude the named user accounts from the dump files

|includeUsers
|array of strings
|----
|util.dumpInstance("C:/data/inst_dump", {includeUsers: ["'user_name'@'host_name'"]})
|includeUsers

|excludeSchemas
|array of strings
|----
|util.dumpInstance("C:/data/inst_dump", {excludeSchemas: ["sakila", "bank"]})
|Exclude the named schemas from the dump. Note that the information_schema, mysql, ndbinfo, performance_schema, and sys schemas are always excluded from an instance dump.

|includeSchemas
|array of strings
|----
|util.dumpInstance("C:/data/inst_dump", {includeSchemas: ["sakila", "bank"]})
|Include only the named schemas in the dump. If you want to dump one or more of these schemas, you can do this using the schema dump utility util.dumpSchemas().

|events
|true / false
|true
|util.dumpInstance("C:/data/inst_dump", {events: false})
|Include (true) or exclude (false) events for each schema in the dump

|routines
|true / false
|true
|util.dumpInstance("C:/data/inst_dump", {routines: false})
|Include (true) or exclude (false) functions and stored procedures for each schema in the dump.

|===
====

== Creating a dump of the entire database instance (Total of 10 schemas. 60 million rows)

====
''''
====


image::https://github.com/jecastrom/automating_database_migration_to_the_cloud/blob/main/img/instancedump.gif[width=1000]

====
''''
====